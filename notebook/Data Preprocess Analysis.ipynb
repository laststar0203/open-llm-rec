{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ccba7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.dirname(os.path.abspath('.')))\n",
    "sys.path.append(\"D:/document/personal/논문/6차/open-llm-rec/datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71c7c41a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\sinny\\\\anaconda3\\\\envs\\\\llama3\\\\python311.zip',\n",
       " 'C:\\\\Users\\\\sinny\\\\anaconda3\\\\envs\\\\llama3\\\\Lib',\n",
       " 'C:\\\\Users\\\\sinny\\\\anaconda3\\\\envs\\\\llama3\\\\DLLs',\n",
       " 'C:\\\\Users\\\\sinny\\\\anaconda3\\\\envs\\\\llama3',\n",
       " '',\n",
       " 'C:\\\\Users\\\\sinny\\\\anaconda3\\\\envs\\\\llama3\\\\Lib\\\\site-packages',\n",
       " 'D:\\\\document\\\\personal\\\\논문\\\\6차\\\\ollama\\\\study_code\\\\langserve_demo_app',\n",
       " 'C:\\\\Users\\\\sinny\\\\anaconda3\\\\envs\\\\llama3\\\\Lib\\\\site-packages\\\\win32',\n",
       " 'C:\\\\Users\\\\sinny\\\\anaconda3\\\\envs\\\\llama3\\\\Lib\\\\site-packages\\\\win32\\\\lib',\n",
       " 'C:\\\\Users\\\\sinny\\\\anaconda3\\\\envs\\\\llama3\\\\Lib\\\\site-packages\\\\Pythonwin',\n",
       " 'D:\\\\source\\\\personal\\\\rag-service\\\\serve',\n",
       " 'D:/document/personal/논문/6차/open-llm-rec/datasets']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "253338a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84343838",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'model_code' : 'lru',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6d76a9",
   "metadata": {},
   "source": [
    "# Dataset Loader\n",
    "\n",
    "\n",
    "정의된 메소드 기능 해석은 ML-100K Data Analysis.ipynb 참고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "256fe87a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AbstractDataset\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m date\n",
      "\u001b[1;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "from .base import AbstractDataset\n",
    "from .utils import *\n",
    "\n",
    "from datetime import date\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import shutil\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "class ML100KDataset(AbstractDataset):\n",
    "    @classmethod\n",
    "    def code(cls):\n",
    "        return 'ml-100k'\n",
    "\n",
    "    @classmethod\n",
    "    def url(cls):  # as of Sep 2023\n",
    "        return 'https://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
    "\n",
    "    @classmethod\n",
    "    def zip_file_content_is_folder(cls):\n",
    "        return True\n",
    "\n",
    "    @classmethod\n",
    "    def all_raw_file_names(cls):\n",
    "        return ['README',\n",
    "                'movies.csv',\n",
    "                'ratings.csv',\n",
    "                'users.csv']\n",
    "\n",
    "    def maybe_download_raw_dataset(self):\n",
    "        folder_path = self._get_rawdata_folder_path()\n",
    "        if folder_path.is_dir() and\\\n",
    "           all(folder_path.joinpath(filename).is_file() for filename in self.all_raw_file_names()):\n",
    "            print('Raw data already exists. Skip downloading')\n",
    "            return\n",
    "\n",
    "        print(\"Raw file doesn't exist. Downloading...\")\n",
    "        tmproot = Path(tempfile.mkdtemp())\n",
    "        tmpzip = tmproot.joinpath('file.zip')\n",
    "        tmpfolder = tmproot.joinpath('folder')\n",
    "        download(self.url(), tmpzip)\n",
    "        unzip(tmpzip, tmpfolder)\n",
    "        if self.zip_file_content_is_folder():\n",
    "            tmpfolder = tmpfolder.joinpath(os.listdir(tmpfolder)[0])\n",
    "        shutil.move(tmpfolder, folder_path)\n",
    "        shutil.rmtree(tmproot)\n",
    "        print()\n",
    "\n",
    "    def preprocess(self):\n",
    "        dataset_path = self._get_preprocessed_dataset_path()\n",
    "        if dataset_path.is_file():\n",
    "            print('Already preprocessed. Skip preprocessing')\n",
    "            return\n",
    "        if not dataset_path.parent.is_dir():\n",
    "            dataset_path.parent.mkdir(parents=True)\n",
    "        self.maybe_download_raw_dataset()\n",
    "        df = self.load_ratings_df()\n",
    "        meta_raw = self.load_meta_dict()\n",
    "        df = df[df['sid'].isin(meta_raw)]  # filter items without meta info\n",
    "        df = self.filter_triplets(df)\n",
    "        df, umap, smap = self.densify_index(df)\n",
    "        train, val, test = self.split_df(df, len(umap))\n",
    "        meta = {smap[k]: v for k, v in meta_raw.items() if k in smap}\n",
    "        dataset = {'train': train,\n",
    "                   'val': val,\n",
    "                   'test': test,\n",
    "                   'meta': meta,\n",
    "                   'umap': umap,\n",
    "                   'smap': smap}\n",
    "        with dataset_path.open('wb') as f:\n",
    "            pickle.dump(dataset, f)\n",
    "\n",
    "    def load_ratings_df(self):\n",
    "        folder_path = self._get_rawdata_folder_path()\n",
    "        file_path = folder_path.joinpath('ratings.csv')\n",
    "        df = pd.read_csv(file_path)\n",
    "        df.columns = ['uid', 'sid', 'rating', 'timestamp']\n",
    "        return df\n",
    "\n",
    "    def load_meta_dict(self):\n",
    "        folder_path = self._get_rawdata_folder_path()\n",
    "        file_path = folder_path.joinpath('movies.csv')\n",
    "        df = pd.read_csv(file_path, encoding=\"ISO-8859-1\")\n",
    "        meta_dict = {}\n",
    "        for row in df.itertuples():\n",
    "            title = row[2][:-7]  # remove year (optional)\n",
    "            year = row[2][-7:]\n",
    "\n",
    "            title = re.sub('\\(.*?\\)', '', title).strip()\n",
    "            # the rest articles and parentheses are not considered here\n",
    "            if any(', '+x in title.lower()[-5:] for x in ['a', 'an', 'the']):\n",
    "                title_pre = title.split(', ')[:-1]\n",
    "                title_post = title.split(', ')[-1]\n",
    "                title_pre = ', '.join(title_pre)\n",
    "                title = title_post + ' ' + title_pre\n",
    "\n",
    "            meta_dict[row[1]] = title + year\n",
    "        return meta_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e578e095",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama3",
   "language": "python",
   "name": "llama3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
